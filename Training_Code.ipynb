{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Competition Name:**  \n",
        "*CIBMTR - Equity in post-HCT Survival Predictions*\n",
        "\n",
        "**Objective:**  \n",
        "The competition seeks to improve the prediction of transplant survival rates for allogeneic hematopoietic stem cell transplantation (HCT) patients. The emphasis is on generating predictions that are not only accurate but also equitable across diverse racial and demographic groups."
      ],
      "metadata": {
        "id": "jGEY65EJ7eix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Code"
      ],
      "metadata": {
        "id": "dAbmvt2w7So7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Libraries and Load Train Data**"
      ],
      "metadata": {
        "id": "-YKv7nhc99Y9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "import catboost as cb\n",
        "from lightgbm import log_evaluation\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from lifelines import NelsonAalenFitter\n",
        "from lifelines.utils import concordance_index\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# Load Data\n",
        "train = pd.read_csv(\"/content/train.csv\")\n",
        "test = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "# Ensure model directory exists\n",
        "MODEL_DIR = \"/content/models\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "kLRVzbgU-T78"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Engineering**"
      ],
      "metadata": {
        "id": "vuOuq-Hj-fGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering\n",
        "def add_features(df):\n",
        "    df['donor_age_hct_diff'] = df['donor_age'] - df['age_at_hct']\n",
        "    df['comorbidity_karnofsky_ratio'] = df['comorbidity_score'] / (df['karnofsky_score'] + 1)\n",
        "    if 'efs_time' in df.columns:\n",
        "        df['efs_time_log'] = np.log1p(df['efs_time'])\n",
        "    df['year_hct_adjusted'] = df['year_hct'] - 2000\n",
        "    df['is_cyto_score_same'] = (df['cyto_score'] == df['cyto_score_detail']).astype(int)\n",
        "    return df\n",
        "\n",
        "train = add_features(train)\n",
        "test = add_features(test)"
      ],
      "metadata": {
        "id": "nm7-Smrm-yoX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encode Categorical Features**"
      ],
      "metadata": {
        "id": "khZpCxml-89M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Selection\n",
        "RMV = [\"ID\", \"efs\", \"efs_time\", \"y\", \"efs_time_log\"]\n",
        "FEATURES = [c for c in train.columns if c not in RMV]\n",
        "\n",
        "# Encode categorical features\n",
        "for col in train.select_dtypes(include=['object', 'category']).columns:\n",
        "    train[col] = train[col].astype('category').cat.codes\n",
        "    test[col] = test[col].astype('category').cat.codes"
      ],
      "metadata": {
        "id": "4jJwPOvK-98P"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nelson-Aalen Target Transformation**"
      ],
      "metadata": {
        "id": "O4BlPAWu_LVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nelson-Aalen Target Transformation\n",
        "def create_nelson(data):\n",
        "    naf = NelsonAalenFitter(nelson_aalen_smoothing=0)\n",
        "    naf.fit(durations=data['efs_time'], event_observed=data['efs'])\n",
        "    return naf.cumulative_hazard_at_times(data['efs_time']).values * -1\n",
        "\n",
        "train[\"y_nel\"] = create_nelson(train)\n",
        "train.loc[train.efs == 0, \"y_nel\"] = (-(-train.loc[train.efs == 0, \"y_nel\"])**0.5)"
      ],
      "metadata": {
        "id": "GlWmWgMC_L-o"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pairwise Logit Transform**"
      ],
      "metadata": {
        "id": "UPiIZOgs_Vjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pairwise Logit Transform\n",
        "def logit_transform(y, eps=2e-2, eps_mul=1.1):\n",
        "    y = (y - y.min() + eps) / (y.max() - y.min() + eps_mul * eps)\n",
        "    return np.log(y / (1 - y))\n",
        "\n",
        "train[\"y_transformed\"] = logit_transform(train[\"y_nel\"])"
      ],
      "metadata": {
        "id": "lvqAMlkS_V2G"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stratified K-Folds**"
      ],
      "metadata": {
        "id": "Tc8PxV4N_o-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stratified K-Folds\n",
        "FOLDS = 15\n",
        "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
        "train[\"fold\"] = -1\n",
        "for fold, (_, val_idx) in enumerate(skf.split(train, train[\"race_group\"])):\n",
        "    train.loc[val_idx, \"fold\"] = fold"
      ],
      "metadata": {
        "id": "7iZsO37P_pqW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LGB MODEL PARAMETERS**"
      ],
      "metadata": {
        "id": "SPDa7zaa_0dg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Parameters\n",
        "lgb_params = {\n",
        "    \"objective\": \"regression\",\n",
        "    \"metric\": \"rmse\",\n",
        "    \"learning_rate\": 0.04,\n",
        "    \"max_depth\": 9,\n",
        "    \"num_leaves\": 64,\n",
        "    \"subsample\": 0.6,\n",
        "    \"colsample_bytree\": 0.6,\n",
        "    \"random_state\": 42\n",
        "}"
      ],
      "metadata": {
        "id": "lnUbAzEB_0we"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGB MODEL PARAMETERS**"
      ],
      "metadata": {
        "id": "F829V9cL_-Dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_params = {\n",
        "    \"objective\": \"reg:squarederror\",\n",
        "    \"learning_rate\": 0.02,\n",
        "    \"max_depth\": 6,\n",
        "    \"colsample_bytree\": 0.6,\n",
        "    \"subsample\": 0.8,\n",
        "    \"n_estimators\": 6000,\n",
        "    \"min_child_weight\": 3,\n",
        "    \"early_stopping_rounds\": 500,\n",
        "    \"random_state\": 42,\n",
        "    \"gamma\": 0.2,\n",
        "    \"reg_alpha\": 0.1,\n",
        "    \"reg_lambda\": 0.8\n",
        "}"
      ],
      "metadata": {
        "id": "4wQ2jb2W_-UG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CATBOOST MODEL PARAMETERS**"
      ],
      "metadata": {
        "id": "1UZ5QuLgALln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_params = {\n",
        "    \"loss_function\": \"RMSE\",\n",
        "    \"learning_rate\": 0.045,\n",
        "    \"depth\": 8,\n",
        "    \"iterations\": 5000,\n",
        "    \"random_strength\": 0.2,\n",
        "    \"l2_leaf_reg\": 5,\n",
        "    \"bagging_temperature\": 0.6,\n",
        "    \"random_seed\": 42\n",
        "}"
      ],
      "metadata": {
        "id": "jHc5FJPWAL1G"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train & Save Models**"
      ],
      "metadata": {
        "id": "f6zyoJW_AaPo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC7fsbDg6rHN",
        "outputId": "f5700944-39d2-4040-89ed-f6917a982684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Fold 1\n",
            "[0]\tvalidation_0-rmse:2.33474\n",
            "[500]\tvalidation_0-rmse:2.08393\n",
            "[1000]\tvalidation_0-rmse:2.07002\n",
            "[1500]\tvalidation_0-rmse:2.07291\n",
            "[1629]\tvalidation_0-rmse:2.07526\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014766 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1158\n",
            "[LightGBM] [Info] Number of data points in the train set: 26880, number of used features: 61\n",
            "[LightGBM] [Info] Start training from score -1.154759\n",
            "0:\tlearn: 2.3321653\ttest: 2.3278996\tbest: 2.3278996 (0)\ttotal: 65.5ms\tremaining: 5m 27s\n",
            "500:\tlearn: 1.8324950\ttest: 2.0759756\tbest: 2.0759270 (499)\ttotal: 8.47s\tremaining: 1m 16s\n",
            "1000:\tlearn: 1.6255424\ttest: 2.0773012\tbest: 2.0753050 (534)\ttotal: 17s\tremaining: 1m 7s\n",
            "1500:\tlearn: 1.4671445\ttest: 2.0830741\tbest: 2.0753050 (534)\ttotal: 24s\tremaining: 56s\n",
            "2000:\tlearn: 1.3363716\ttest: 2.0877617\tbest: 2.0753050 (534)\ttotal: 32.6s\tremaining: 48.8s\n",
            "2500:\tlearn: 1.2260594\ttest: 2.0964265\tbest: 2.0753050 (534)\ttotal: 40.9s\tremaining: 40.8s\n",
            "3000:\tlearn: 1.1317238\ttest: 2.1027827\tbest: 2.0753050 (534)\ttotal: 48.2s\tremaining: 32.1s\n",
            "3500:\tlearn: 1.0469789\ttest: 2.1096094\tbest: 2.0753050 (534)\ttotal: 56.9s\tremaining: 24.4s\n",
            "4000:\tlearn: 0.9713906\ttest: 2.1155712\tbest: 2.0753050 (534)\ttotal: 1m 5s\tremaining: 16.3s\n",
            "4500:\tlearn: 0.9057238\ttest: 2.1197104\tbest: 2.0753050 (534)\ttotal: 1m 13s\tremaining: 8.1s\n",
            "4999:\tlearn: 0.8476776\ttest: 2.1243341\tbest: 2.0753050 (534)\ttotal: 1m 21s\tremaining: 0us\n",
            "\n",
            "bestTest = 2.075304972\n",
            "bestIteration = 534\n",
            "\n",
            "Shrink model to first 535 iterations.\n",
            "Training Fold 2\n",
            "[0]\tvalidation_0-rmse:2.35639\n",
            "[500]\tvalidation_0-rmse:2.11251\n",
            "[1000]\tvalidation_0-rmse:2.10742\n",
            "[1393]\tvalidation_0-rmse:2.10985\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011655 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1158\n",
            "[LightGBM] [Info] Number of data points in the train set: 26880, number of used features: 61\n",
            "[LightGBM] [Info] Start training from score -1.157849\n",
            "0:\tlearn: 2.3305619\ttest: 2.3488214\tbest: 2.3488214 (0)\ttotal: 13.7ms\tremaining: 1m 8s\n",
            "500:\tlearn: 1.8296121\ttest: 2.1094249\tbest: 2.1093206 (491)\ttotal: 8.49s\tremaining: 1m 16s\n",
            "1000:\tlearn: 1.6252320\ttest: 2.1085803\tbest: 2.1040905 (729)\ttotal: 15.6s\tremaining: 1m 2s\n",
            "1500:\tlearn: 1.4680481\ttest: 2.1097211\tbest: 2.1040905 (729)\ttotal: 26.5s\tremaining: 1m 1s\n",
            "2000:\tlearn: 1.3386907\ttest: 2.1121383\tbest: 2.1040905 (729)\ttotal: 35.1s\tremaining: 52.6s\n",
            "2500:\tlearn: 1.2297647\ttest: 2.1164775\tbest: 2.1040905 (729)\ttotal: 43.4s\tremaining: 43.4s\n",
            "3000:\tlearn: 1.1337851\ttest: 2.1232042\tbest: 2.1040905 (729)\ttotal: 50.8s\tremaining: 33.8s\n",
            "3500:\tlearn: 1.0513549\ttest: 2.1270303\tbest: 2.1040905 (729)\ttotal: 1m 2s\tremaining: 26.7s\n",
            "4000:\tlearn: 0.9774199\ttest: 2.1293604\tbest: 2.1040905 (729)\ttotal: 1m 11s\tremaining: 17.8s\n",
            "4500:\tlearn: 0.9119994\ttest: 2.1330558\tbest: 2.1040905 (729)\ttotal: 1m 18s\tremaining: 8.75s\n",
            "4999:\tlearn: 0.8535509\ttest: 2.1356383\tbest: 2.1040905 (729)\ttotal: 1m 27s\tremaining: 0us\n",
            "\n",
            "bestTest = 2.104090514\n",
            "bestIteration = 729\n",
            "\n",
            "Shrink model to first 730 iterations.\n",
            "Training Fold 3\n",
            "[0]\tvalidation_0-rmse:2.39479\n",
            "[500]\tvalidation_0-rmse:2.13852\n",
            "[1000]\tvalidation_0-rmse:2.11901\n",
            "[1500]\tvalidation_0-rmse:2.11850\n",
            "[1799]\tvalidation_0-rmse:2.12109\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011647 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1157\n",
            "[LightGBM] [Info] Number of data points in the train set: 26880, number of used features: 61\n",
            "[LightGBM] [Info] Start training from score -1.155388\n",
            "0:\tlearn: 2.3275627\ttest: 2.3873030\tbest: 2.3873030 (0)\ttotal: 19.2ms\tremaining: 1m 35s\n",
            "500:\tlearn: 1.8291905\ttest: 2.1443700\tbest: 2.1435408 (489)\ttotal: 7.75s\tremaining: 1m 9s\n",
            "1000:\tlearn: 1.6245904\ttest: 2.1341765\tbest: 2.1325007 (887)\ttotal: 16.6s\tremaining: 1m 6s\n",
            "1500:\tlearn: 1.4645306\ttest: 2.1328385\tbest: 2.1305779 (1227)\ttotal: 23.6s\tremaining: 55s\n",
            "2000:\tlearn: 1.3364852\ttest: 2.1350549\tbest: 2.1305779 (1227)\ttotal: 32.1s\tremaining: 48.1s\n",
            "2500:\tlearn: 1.2260211\ttest: 2.1400554\tbest: 2.1305779 (1227)\ttotal: 40.6s\tremaining: 40.6s\n",
            "3000:\tlearn: 1.1302621\ttest: 2.1436299\tbest: 2.1305779 (1227)\ttotal: 47.8s\tremaining: 31.8s\n",
            "3500:\tlearn: 1.0477555\ttest: 2.1491270\tbest: 2.1305779 (1227)\ttotal: 56.4s\tremaining: 24.1s\n",
            "4000:\tlearn: 0.9745977\ttest: 2.1520475\tbest: 2.1305779 (1227)\ttotal: 1m 4s\tremaining: 16.2s\n",
            "4500:\tlearn: 0.9100301\ttest: 2.1594221\tbest: 2.1305779 (1227)\ttotal: 1m 12s\tremaining: 7.98s\n",
            "4999:\tlearn: 0.8505757\ttest: 2.1628377\tbest: 2.1305779 (1227)\ttotal: 1m 20s\tremaining: 0us\n",
            "\n",
            "bestTest = 2.130577869\n",
            "bestIteration = 1227\n",
            "\n",
            "Shrink model to first 1228 iterations.\n",
            "Training Fold 4\n",
            "[0]\tvalidation_0-rmse:2.35207\n",
            "[500]\tvalidation_0-rmse:2.10244\n",
            "[1000]\tvalidation_0-rmse:2.08445\n",
            "[1500]\tvalidation_0-rmse:2.08469\n",
            "[1614]\tvalidation_0-rmse:2.08435\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011516 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1158\n",
            "[LightGBM] [Info] Number of data points in the train set: 26880, number of used features: 61\n",
            "[LightGBM] [Info] Start training from score -1.156442\n",
            "0:\tlearn: 2.3310471\ttest: 2.3456003\tbest: 2.3456003 (0)\ttotal: 14.3ms\tremaining: 1m 11s\n",
            "500:\tlearn: 1.8270012\ttest: 2.0943464\tbest: 2.0941822 (488)\ttotal: 8.44s\tremaining: 1m 15s\n",
            "1000:\tlearn: 1.6228333\ttest: 2.0881267\tbest: 2.0870172 (935)\ttotal: 16.9s\tremaining: 1m 7s\n",
            "1500:\tlearn: 1.4663277\ttest: 2.0890449\tbest: 2.0870172 (935)\ttotal: 24s\tremaining: 56s\n",
            "2000:\tlearn: 1.3342657\ttest: 2.0981314\tbest: 2.0870172 (935)\ttotal: 32.5s\tremaining: 48.7s\n",
            "2500:\tlearn: 1.2251897\ttest: 2.1040169\tbest: 2.0870172 (935)\ttotal: 40.6s\tremaining: 40.6s\n",
            "3000:\tlearn: 1.1326370\ttest: 2.1106051\tbest: 2.0870172 (935)\ttotal: 48.2s\tremaining: 32.1s\n",
            "3500:\tlearn: 1.0498309\ttest: 2.1150071\tbest: 2.0870172 (935)\ttotal: 56.8s\tremaining: 24.3s\n",
            "4000:\tlearn: 0.9774283\ttest: 2.1201470\tbest: 2.0870172 (935)\ttotal: 1m 3s\tremaining: 16s\n",
            "4500:\tlearn: 0.9125462\ttest: 2.1235376\tbest: 2.0870172 (935)\ttotal: 1m 12s\tremaining: 8.04s\n",
            "4999:\tlearn: 0.8559765\ttest: 2.1280696\tbest: 2.0870172 (935)\ttotal: 1m 21s\tremaining: 0us\n",
            "\n",
            "bestTest = 2.087017172\n",
            "bestIteration = 935\n",
            "\n",
            "Shrink model to first 936 iterations.\n",
            "Training Fold 5\n",
            "[0]\tvalidation_0-rmse:2.34016\n",
            "[500]\tvalidation_0-rmse:2.10575\n",
            "[1000]\tvalidation_0-rmse:2.10786\n",
            "[1140]\tvalidation_0-rmse:2.10822\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012575 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1158\n",
            "[LightGBM] [Info] Number of data points in the train set: 26880, number of used features: 61\n",
            "[LightGBM] [Info] Start training from score -1.155827\n",
            "0:\tlearn: 2.3317238\ttest: 2.3329022\tbest: 2.3329022 (0)\ttotal: 14.1ms\tremaining: 1m 10s\n",
            "500:\tlearn: 1.8286626\ttest: 2.1010596\tbest: 2.1005816 (489)\ttotal: 7s\tremaining: 1m 2s\n",
            "1000:\tlearn: 1.6291003\ttest: 2.0982895\tbest: 2.0982895 (1000)\ttotal: 15.4s\tremaining: 1m 1s\n",
            "1500:\tlearn: 1.4720183\ttest: 2.1026323\tbest: 2.0980894 (1011)\ttotal: 23.9s\tremaining: 55.7s\n",
            "2000:\tlearn: 1.3442288\ttest: 2.1062814\tbest: 2.0980894 (1011)\ttotal: 30.9s\tremaining: 46.3s\n",
            "2500:\tlearn: 1.2328416\ttest: 2.1121538\tbest: 2.0980894 (1011)\ttotal: 39.5s\tremaining: 39.5s\n",
            "3000:\tlearn: 1.1378768\ttest: 2.1180998\tbest: 2.0980894 (1011)\ttotal: 48s\tremaining: 32s\n",
            "3500:\tlearn: 1.0549209\ttest: 2.1244384\tbest: 2.0980894 (1011)\ttotal: 55.1s\tremaining: 23.6s\n",
            "4000:\tlearn: 0.9784907\ttest: 2.1273339\tbest: 2.0980894 (1011)\ttotal: 1m 3s\tremaining: 15.9s\n",
            "4500:\tlearn: 0.9116004\ttest: 2.1313843\tbest: 2.0980894 (1011)\ttotal: 1m 11s\tremaining: 7.98s\n",
            "4999:\tlearn: 0.8512698\ttest: 2.1364659\tbest: 2.0980894 (1011)\ttotal: 1m 19s\tremaining: 0us\n",
            "\n",
            "bestTest = 2.098089376\n",
            "bestIteration = 1011\n",
            "\n",
            "Shrink model to first 1012 iterations.\n",
            "Training Fold 6\n",
            "[0]\tvalidation_0-rmse:2.31137\n",
            "[500]\tvalidation_0-rmse:2.06581\n",
            "[1000]\tvalidation_0-rmse:2.05689\n",
            "[1500]\tvalidation_0-rmse:2.05910\n",
            "[1650]\tvalidation_0-rmse:2.05915\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011504 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1158\n",
            "[LightGBM] [Info] Number of data points in the train set: 26880, number of used features: 61\n",
            "[LightGBM] [Info] Start training from score -1.154752\n",
            "0:\tlearn: 2.3338431\ttest: 2.3038270\tbest: 2.3038270 (0)\ttotal: 13.6ms\tremaining: 1m 8s\n",
            "500:\tlearn: 1.8302110\ttest: 2.0570876\tbest: 2.0569269 (494)\ttotal: 6.97s\tremaining: 1m 2s\n",
            "1000:\tlearn: 1.6279762\ttest: 2.0586704\tbest: 2.0548712 (709)\ttotal: 15.4s\tremaining: 1m 1s\n",
            "1500:\tlearn: 1.4719328\ttest: 2.0624137\tbest: 2.0548712 (709)\ttotal: 23.8s\tremaining: 55.4s\n",
            "2000:\tlearn: 1.3409587\ttest: 2.0710673\tbest: 2.0548712 (709)\ttotal: 30.9s\tremaining: 46.3s\n",
            "2500:\tlearn: 1.2326932\ttest: 2.0781404\tbest: 2.0548712 (709)\ttotal: 39.4s\tremaining: 39.3s\n",
            "3000:\tlearn: 1.1389665\ttest: 2.0845763\tbest: 2.0548712 (709)\ttotal: 46.9s\tremaining: 31.3s\n",
            "3500:\tlearn: 1.0573643\ttest: 2.0889085\tbest: 2.0548712 (709)\ttotal: 54.9s\tremaining: 23.5s\n",
            "4000:\tlearn: 0.9824053\ttest: 2.0920517\tbest: 2.0548712 (709)\ttotal: 1m 3s\tremaining: 15.9s\n",
            "4500:\tlearn: 0.9153407\ttest: 2.0970706\tbest: 2.0548712 (709)\ttotal: 1m 10s\tremaining: 7.83s\n",
            "4999:\tlearn: 0.8537926\ttest: 2.1009432\tbest: 2.0548712 (709)\ttotal: 1m 19s\tremaining: 0us\n",
            "\n",
            "bestTest = 2.054871199\n",
            "bestIteration = 709\n",
            "\n",
            "Shrink model to first 710 iterations.\n",
            "Training Fold 7\n",
            "[0]\tvalidation_0-rmse:2.31672\n",
            "[500]\tvalidation_0-rmse:2.06001\n",
            "[1000]\tvalidation_0-rmse:2.05951\n",
            "[1258]\tvalidation_0-rmse:2.05976\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011811 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1158\n",
            "[LightGBM] [Info] Number of data points in the train set: 26880, number of used features: 61\n",
            "[LightGBM] [Info] Start training from score -1.150597\n",
            "0:\tlearn: 2.3334308\ttest: 2.3094325\tbest: 2.3094325 (0)\ttotal: 13.1ms\tremaining: 1m 5s\n",
            "500:\tlearn: 1.8327106\ttest: 2.0636934\tbest: 2.0631082 (492)\ttotal: 8.32s\tremaining: 1m 14s\n",
            "1000:\tlearn: 1.6262414\ttest: 2.0615839\tbest: 2.0598477 (935)\ttotal: 15.8s\tremaining: 1m 2s\n",
            "1500:\tlearn: 1.4678851\ttest: 2.0666020\tbest: 2.0598477 (935)\ttotal: 23.8s\tremaining: 55.4s\n",
            "2000:\tlearn: 1.3385476\ttest: 2.0747441\tbest: 2.0598477 (935)\ttotal: 32.3s\tremaining: 48.4s\n",
            "2500:\tlearn: 1.2276065\ttest: 2.0794017\tbest: 2.0598477 (935)\ttotal: 39.4s\tremaining: 39.4s\n",
            "3000:\tlearn: 1.1326498\ttest: 2.0844502\tbest: 2.0598477 (935)\ttotal: 48s\tremaining: 31.9s\n",
            "3500:\tlearn: 1.0498755\ttest: 2.0888600\tbest: 2.0598477 (935)\ttotal: 56.6s\tremaining: 24.2s\n",
            "4000:\tlearn: 0.9776006\ttest: 2.0904870\tbest: 2.0598477 (935)\ttotal: 1m 3s\tremaining: 15.9s\n",
            "4500:\tlearn: 0.9098242\ttest: 2.0949442\tbest: 2.0598477 (935)\ttotal: 1m 12s\tremaining: 8.02s\n",
            "4999:\tlearn: 0.8502500\ttest: 2.0986503\tbest: 2.0598477 (935)\ttotal: 1m 20s\tremaining: 0us\n",
            "\n",
            "bestTest = 2.059847687\n",
            "bestIteration = 935\n",
            "\n",
            "Shrink model to first 936 iterations.\n",
            "Training Fold 8\n",
            "[0]\tvalidation_0-rmse:2.31178\n",
            "[500]\tvalidation_0-rmse:2.09272\n",
            "[1000]\tvalidation_0-rmse:2.09235\n",
            "[1061]\tvalidation_0-rmse:2.09406\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016117 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1158\n",
            "[LightGBM] [Info] Number of data points in the train set: 26880, number of used features: 61\n",
            "[LightGBM] [Info] Start training from score -1.156393\n",
            "0:\tlearn: 2.3336611\ttest: 2.3048424\tbest: 2.3048424 (0)\ttotal: 25.8ms\tremaining: 2m 8s\n",
            "500:\tlearn: 1.8322771\ttest: 2.0920257\tbest: 2.0917059 (442)\ttotal: 7.17s\tremaining: 1m 4s\n",
            "1000:\tlearn: 1.6241257\ttest: 2.0926952\tbest: 2.0891303 (795)\ttotal: 15.7s\tremaining: 1m 2s\n",
            "1500:\tlearn: 1.4657020\ttest: 2.0961653\tbest: 2.0891303 (795)\ttotal: 22.8s\tremaining: 53.2s\n",
            "2000:\tlearn: 1.3342915\ttest: 2.1034004\tbest: 2.0891303 (795)\ttotal: 31.4s\tremaining: 47.1s\n",
            "2500:\tlearn: 1.2246748\ttest: 2.1101843\tbest: 2.0891303 (795)\ttotal: 40.1s\tremaining: 40.1s\n",
            "3000:\tlearn: 1.1304081\ttest: 2.1136650\tbest: 2.0891303 (795)\ttotal: 47.3s\tremaining: 31.5s\n",
            "3500:\tlearn: 1.0480270\ttest: 2.1166101\tbest: 2.0891303 (795)\ttotal: 56s\tremaining: 24s\n",
            "4000:\tlearn: 0.9723813\ttest: 2.1204588\tbest: 2.0891303 (795)\ttotal: 1m 4s\tremaining: 16.1s\n",
            "4500:\tlearn: 0.9078128\ttest: 2.1239492\tbest: 2.0891303 (795)\ttotal: 1m 11s\tremaining: 7.96s\n",
            "4999:\tlearn: 0.8486535\ttest: 2.1274275\tbest: 2.0891303 (795)\ttotal: 1m 20s\tremaining: 0us\n",
            "\n",
            "bestTest = 2.089130277\n",
            "bestIteration = 795\n",
            "\n",
            "Shrink model to first 796 iterations.\n",
            "Training Fold 9\n",
            "[0]\tvalidation_0-rmse:2.32913\n",
            "[500]\tvalidation_0-rmse:2.06330\n",
            "[1000]\tvalidation_0-rmse:2.05667\n",
            "[1404]\tvalidation_0-rmse:2.06089\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012211 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1158\n",
            "[LightGBM] [Info] Number of data points in the train set: 26880, number of used features: 61\n",
            "[LightGBM] [Info] Start training from score -1.160110\n",
            "0:\tlearn: 2.3325623\ttest: 2.3211716\tbest: 2.3211716 (0)\ttotal: 13.6ms\tremaining: 1m 7s\n",
            "500:\tlearn: 1.8293261\ttest: 2.0616452\tbest: 2.0615876 (431)\ttotal: 8.44s\tremaining: 1m 15s\n",
            "1000:\tlearn: 1.6222770\ttest: 2.0656302\tbest: 2.0601823 (536)\ttotal: 16.9s\tremaining: 1m 7s\n",
            "1500:\tlearn: 1.4643292\ttest: 2.0730675\tbest: 2.0601823 (536)\ttotal: 24s\tremaining: 55.9s\n",
            "2000:\tlearn: 1.3397525\ttest: 2.0773934\tbest: 2.0601823 (536)\ttotal: 32.4s\tremaining: 48.6s\n",
            "2500:\tlearn: 1.2300276\ttest: 2.0854488\tbest: 2.0601823 (536)\ttotal: 39.6s\tremaining: 39.6s\n",
            "3000:\tlearn: 1.1358118\ttest: 2.0923845\tbest: 2.0601823 (536)\ttotal: 48.1s\tremaining: 32.1s\n",
            "3500:\tlearn: 1.0530190\ttest: 2.0989880\tbest: 2.0601823 (536)\ttotal: 56.8s\tremaining: 24.3s\n",
            "4000:\tlearn: 0.9807200\ttest: 2.1055839\tbest: 2.0601823 (536)\ttotal: 1m 3s\tremaining: 16s\n",
            "4500:\tlearn: 0.9141683\ttest: 2.1088790\tbest: 2.0601823 (536)\ttotal: 1m 12s\tremaining: 8.04s\n",
            "4999:\tlearn: 0.8551613\ttest: 2.1147862\tbest: 2.0601823 (536)\ttotal: 1m 21s\tremaining: 0us\n",
            "\n",
            "bestTest = 2.060182257\n",
            "bestIteration = 536\n",
            "\n",
            "Shrink model to first 537 iterations.\n",
            "Training Fold 10\n",
            "[0]\tvalidation_0-rmse:2.28510\n",
            "[500]\tvalidation_0-rmse:2.06989\n",
            "[1000]\tvalidation_0-rmse:2.06949\n",
            "[1100]\tvalidation_0-rmse:2.07009\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011417 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1158\n",
            "[LightGBM] [Info] Number of data points in the train set: 26880, number of used features: 61\n",
            "[LightGBM] [Info] Start training from score -1.149386\n",
            "0:\tlearn: 2.3353955\ttest: 2.2775251\tbest: 2.2775251 (0)\ttotal: 13.3ms\tremaining: 1m 6s\n",
            "500:\tlearn: 1.8308963\ttest: 2.0663942\tbest: 2.0641174 (479)\ttotal: 6.98s\tremaining: 1m 2s\n",
            "1000:\tlearn: 1.6264566\ttest: 2.0678954\tbest: 2.0641174 (479)\ttotal: 15.4s\tremaining: 1m 1s\n",
            "1500:\tlearn: 1.4660963\ttest: 2.0774119\tbest: 2.0641174 (479)\ttotal: 23.8s\tremaining: 55.4s\n",
            "2000:\tlearn: 1.3388420\ttest: 2.0841419\tbest: 2.0641174 (479)\ttotal: 30.8s\tremaining: 46.1s\n",
            "2500:\tlearn: 1.2308268\ttest: 2.0905604\tbest: 2.0641174 (479)\ttotal: 39.2s\tremaining: 39.2s\n",
            "3000:\tlearn: 1.1332432\ttest: 2.0945563\tbest: 2.0641174 (479)\ttotal: 47.4s\tremaining: 31.6s\n",
            "3500:\tlearn: 1.0523288\ttest: 2.0973911\tbest: 2.0641174 (479)\ttotal: 54.8s\tremaining: 23.5s\n",
            "4000:\tlearn: 0.9783113\ttest: 2.1025106\tbest: 2.0641174 (479)\ttotal: 1m 3s\tremaining: 15.8s\n",
            "4500:\tlearn: 0.9129824\ttest: 2.1049909\tbest: 2.0641174 (479)\ttotal: 1m 10s\tremaining: 7.81s\n",
            "4999:\tlearn: 0.8550856\ttest: 2.1088587\tbest: 2.0641174 (479)\ttotal: 1m 19s\tremaining: 0us\n",
            "\n",
            "bestTest = 2.064117358\n",
            "bestIteration = 479\n",
            "\n",
            "Shrink model to first 480 iterations.\n",
            "Training Fold 11\n",
            "[0]\tvalidation_0-rmse:2.36294\n",
            "[500]\tvalidation_0-rmse:2.13209\n",
            "[1000]\tvalidation_0-rmse:2.12135\n",
            "[1485]\tvalidation_0-rmse:2.12536\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011488 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1158\n",
            "[LightGBM] [Info] Number of data points in the train set: 26880, number of used features: 61\n",
            "[LightGBM] [Info] Start training from score -1.156731\n",
            "0:\tlearn: 2.3297711\ttest: 2.3559026\tbest: 2.3559026 (0)\ttotal: 18.5ms\tremaining: 1m 32s\n",
            "500:\tlearn: 1.8294197\ttest: 2.1349262\tbest: 2.1349262 (500)\ttotal: 8.32s\tremaining: 1m 14s\n",
            "1000:\tlearn: 1.6236229\ttest: 2.1328012\tbest: 2.1311851 (891)\ttotal: 16.8s\tremaining: 1m 7s\n",
            "1500:\tlearn: 1.4620588\ttest: 2.1348616\tbest: 2.1311851 (891)\ttotal: 23.9s\tremaining: 55.8s\n",
            "2000:\tlearn: 1.3323145\ttest: 2.1384204\tbest: 2.1311851 (891)\ttotal: 32.5s\tremaining: 48.7s\n",
            "2500:\tlearn: 1.2219147\ttest: 2.1430077\tbest: 2.1311851 (891)\ttotal: 41.2s\tremaining: 41.2s\n",
            "3000:\tlearn: 1.1308487\ttest: 2.1465714\tbest: 2.1311851 (891)\ttotal: 48.3s\tremaining: 32.2s\n",
            "3500:\tlearn: 1.0490531\ttest: 2.1517000\tbest: 2.1311851 (891)\ttotal: 56.9s\tremaining: 24.4s\n",
            "4000:\tlearn: 0.9737792\ttest: 2.1556562\tbest: 2.1311851 (891)\ttotal: 1m 5s\tremaining: 16.4s\n",
            "4500:\tlearn: 0.9088573\ttest: 2.1603924\tbest: 2.1311851 (891)\ttotal: 1m 12s\tremaining: 8.09s\n",
            "4999:\tlearn: 0.8492767\ttest: 2.1622945\tbest: 2.1311851 (891)\ttotal: 1m 21s\tremaining: 0us\n",
            "\n",
            "bestTest = 2.131185131\n",
            "bestIteration = 891\n",
            "\n",
            "Shrink model to first 892 iterations.\n",
            "Training Fold 12\n",
            "[0]\tvalidation_0-rmse:2.36074\n",
            "[500]\tvalidation_0-rmse:2.14464\n",
            "[1000]\tvalidation_0-rmse:2.13877\n",
            "[1413]\tvalidation_0-rmse:2.14151\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011664 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1158\n",
            "[LightGBM] [Info] Number of data points in the train set: 26880, number of used features: 61\n",
            "[LightGBM] [Info] Start training from score -1.155115\n",
            "0:\tlearn: 2.3297844\ttest: 2.3541095\tbest: 2.3541095 (0)\ttotal: 13ms\tremaining: 1m 5s\n",
            "500:\tlearn: 1.8283483\ttest: 2.1499516\tbest: 2.1497736 (471)\ttotal: 8.37s\tremaining: 1m 15s\n",
            "1000:\tlearn: 1.6246497\ttest: 2.1472153\tbest: 2.1451489 (920)\ttotal: 16.1s\tremaining: 1m 4s\n",
            "1500:\tlearn: 1.4679240\ttest: 2.1494302\tbest: 2.1451489 (920)\ttotal: 23.9s\tremaining: 55.8s\n",
            "2000:\tlearn: 1.3373625\ttest: 2.1533342\tbest: 2.1451489 (920)\ttotal: 32.5s\tremaining: 48.6s\n",
            "2500:\tlearn: 1.2300799\ttest: 2.1597792\tbest: 2.1451489 (920)\ttotal: 39.5s\tremaining: 39.5s\n",
            "3000:\tlearn: 1.1357037\ttest: 2.1673391\tbest: 2.1451489 (920)\ttotal: 48.2s\tremaining: 32.1s\n",
            "3500:\tlearn: 1.0539300\ttest: 2.1700646\tbest: 2.1451489 (920)\ttotal: 56.8s\tremaining: 24.3s\n",
            "4000:\tlearn: 0.9804619\ttest: 2.1730617\tbest: 2.1451489 (920)\ttotal: 1m 3s\tremaining: 16s\n",
            "4500:\tlearn: 0.9153031\ttest: 2.1779154\tbest: 2.1451489 (920)\ttotal: 1m 12s\tremaining: 8.04s\n",
            "4999:\tlearn: 0.8566345\ttest: 2.1815131\tbest: 2.1451489 (920)\ttotal: 1m 21s\tremaining: 0us\n",
            "\n",
            "bestTest = 2.145148888\n",
            "bestIteration = 920\n",
            "\n",
            "Shrink model to first 921 iterations.\n",
            "Training Fold 13\n",
            "[0]\tvalidation_0-rmse:2.31077\n",
            "[500]\tvalidation_0-rmse:2.10529\n",
            "[1000]\tvalidation_0-rmse:2.09682\n",
            "[1500]\tvalidation_0-rmse:2.10483\n",
            "[1637]\tvalidation_0-rmse:2.10669\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011453 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1158\n",
            "[LightGBM] [Info] Number of data points in the train set: 26880, number of used features: 61\n",
            "[LightGBM] [Info] Start training from score -1.154614\n",
            "0:\tlearn: 2.3336317\ttest: 2.3044696\tbest: 2.3044696 (0)\ttotal: 12.9ms\tremaining: 1m 4s\n",
            "500:\tlearn: 1.8257518\ttest: 2.1118660\tbest: 2.1114299 (393)\ttotal: 8.29s\tremaining: 1m 14s\n",
            "1000:\tlearn: 1.6252767\ttest: 2.1146957\tbest: 2.1108692 (833)\ttotal: 15.2s\tremaining: 1m\n",
            "1500:\tlearn: 1.4643275\ttest: 2.1222550\tbest: 2.1108692 (833)\ttotal: 23.6s\tremaining: 55s\n",
            "2000:\tlearn: 1.3330978\ttest: 2.1287257\tbest: 2.1108692 (833)\ttotal: 32s\tremaining: 48s\n",
            "2500:\tlearn: 1.2214054\ttest: 2.1358881\tbest: 2.1108692 (833)\ttotal: 39.1s\tremaining: 39.1s\n",
            "3000:\tlearn: 1.1245852\ttest: 2.1397895\tbest: 2.1108692 (833)\ttotal: 47.7s\tremaining: 31.7s\n",
            "3500:\tlearn: 1.0413784\ttest: 2.1442972\tbest: 2.1108692 (833)\ttotal: 55.8s\tremaining: 23.9s\n",
            "4000:\tlearn: 0.9653746\ttest: 2.1496826\tbest: 2.1108692 (833)\ttotal: 1m 3s\tremaining: 15.8s\n",
            "4500:\tlearn: 0.8998131\ttest: 2.1555087\tbest: 2.1108692 (833)\ttotal: 1m 11s\tremaining: 7.96s\n",
            "4999:\tlearn: 0.8410142\ttest: 2.1588706\tbest: 2.1108692 (833)\ttotal: 1m 18s\tremaining: 0us\n",
            "\n",
            "bestTest = 2.110869155\n",
            "bestIteration = 833\n",
            "\n",
            "Shrink model to first 834 iterations.\n",
            "Training Fold 14\n",
            "[0]\tvalidation_0-rmse:2.35464\n",
            "[500]\tvalidation_0-rmse:2.08999\n",
            "[1000]\tvalidation_0-rmse:2.08153\n",
            "[1341]\tvalidation_0-rmse:2.08373\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011550 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1157\n",
            "[LightGBM] [Info] Number of data points in the train set: 26880, number of used features: 61\n",
            "[LightGBM] [Info] Start training from score -1.159179\n",
            "0:\tlearn: 2.3307450\ttest: 2.3466376\tbest: 2.3466376 (0)\ttotal: 12.8ms\tremaining: 1m 4s\n",
            "500:\tlearn: 1.8281093\ttest: 2.0940372\tbest: 2.0938597 (491)\ttotal: 6.9s\tremaining: 1m 1s\n",
            "1000:\tlearn: 1.6235418\ttest: 2.0866892\tbest: 2.0859015 (975)\ttotal: 15.2s\tremaining: 1m\n",
            "1500:\tlearn: 1.4646114\ttest: 2.0921154\tbest: 2.0859015 (975)\ttotal: 23.6s\tremaining: 55.1s\n",
            "2000:\tlearn: 1.3341848\ttest: 2.0957995\tbest: 2.0859015 (975)\ttotal: 30.6s\tremaining: 45.9s\n",
            "2500:\tlearn: 1.2245002\ttest: 2.1000397\tbest: 2.0859015 (975)\ttotal: 39.1s\tremaining: 39.1s\n",
            "3000:\tlearn: 1.1311377\ttest: 2.1050118\tbest: 2.0859015 (975)\ttotal: 46.7s\tremaining: 31.1s\n",
            "3500:\tlearn: 1.0476188\ttest: 2.1112672\tbest: 2.0859015 (975)\ttotal: 54.5s\tremaining: 23.4s\n",
            "4000:\tlearn: 0.9756731\ttest: 2.1149385\tbest: 2.0859015 (975)\ttotal: 1m 3s\tremaining: 15.7s\n",
            "4500:\tlearn: 0.9133771\ttest: 2.1191043\tbest: 2.0859015 (975)\ttotal: 1m 10s\tremaining: 7.78s\n",
            "4999:\tlearn: 0.8538843\ttest: 2.1241177\tbest: 2.0859015 (975)\ttotal: 1m 18s\tremaining: 0us\n",
            "\n",
            "bestTest = 2.0859015\n",
            "bestIteration = 975\n",
            "\n",
            "Shrink model to first 976 iterations.\n",
            "Training Fold 15\n",
            "[0]\tvalidation_0-rmse:2.36970\n",
            "[500]\tvalidation_0-rmse:2.11149\n",
            "[1000]\tvalidation_0-rmse:2.09920\n",
            "[1500]\tvalidation_0-rmse:2.10266\n",
            "[1545]\tvalidation_0-rmse:2.10336\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012107 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1158\n",
            "[LightGBM] [Info] Number of data points in the train set: 26880, number of used features: 61\n",
            "[LightGBM] [Info] Start training from score -1.158189\n",
            "0:\tlearn: 2.3296852\ttest: 2.3621763\tbest: 2.3621763 (0)\ttotal: 25.4ms\tremaining: 2m 6s\n",
            "500:\tlearn: 1.8303671\ttest: 2.1040302\tbest: 2.1040302 (500)\ttotal: 8.36s\tremaining: 1m 15s\n",
            "1000:\tlearn: 1.6291051\ttest: 2.1027501\tbest: 2.0994323 (802)\ttotal: 16.8s\tremaining: 1m 6s\n",
            "1500:\tlearn: 1.4717206\ttest: 2.1091050\tbest: 2.0994323 (802)\ttotal: 23.7s\tremaining: 55.3s\n",
            "2000:\tlearn: 1.3444945\ttest: 2.1150170\tbest: 2.0994323 (802)\ttotal: 32.2s\tremaining: 48.3s\n",
            "2500:\tlearn: 1.2342907\ttest: 2.1182543\tbest: 2.0994323 (802)\ttotal: 40.7s\tremaining: 40.6s\n",
            "3000:\tlearn: 1.1396968\ttest: 2.1252675\tbest: 2.0994323 (802)\ttotal: 47.8s\tremaining: 31.8s\n",
            "3500:\tlearn: 1.0548659\ttest: 2.1290412\tbest: 2.0994323 (802)\ttotal: 56.4s\tremaining: 24.1s\n",
            "4000:\tlearn: 0.9808778\ttest: 2.1342170\tbest: 2.0994323 (802)\ttotal: 1m 4s\tremaining: 16.2s\n",
            "4500:\tlearn: 0.9157317\ttest: 2.1371369\tbest: 2.0994323 (802)\ttotal: 1m 12s\tremaining: 8s\n",
            "4999:\tlearn: 0.8574828\ttest: 2.1391564\tbest: 2.0994323 (802)\ttotal: 1m 20s\tremaining: 0us\n",
            "\n",
            "bestTest = 2.099432268\n",
            "bestIteration = 802\n",
            "\n",
            "Shrink model to first 803 iterations.\n"
          ]
        }
      ],
      "source": [
        "# Train & Save Models\n",
        "oof_preds = np.zeros(len(train))\n",
        "\n",
        "for fold in range(FOLDS):\n",
        "    print(f\"Training Fold {fold+1}\")\n",
        "    x_train = train.loc[train.fold != fold, FEATURES]\n",
        "    y_train = train.loc[train.fold != fold, \"y_transformed\"]\n",
        "    x_valid = train.loc[train.fold == fold, FEATURES]\n",
        "    y_valid = train.loc[train.fold == fold, \"y_transformed\"]\n",
        "\n",
        "    # XGBoost\n",
        "    model_xgb = xgb.XGBRegressor(**xgb_params)\n",
        "    model_xgb.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], verbose=500)\n",
        "    joblib.dump(model_xgb, f\"{MODEL_DIR}/xgb_fold{fold}.pkl\")\n",
        "    oof_preds[train.index[train.fold == fold]] += model_xgb.predict(x_valid) * 0.4\n",
        "\n",
        "    # LightGBM\n",
        "    model_lgb = lgb.LGBMRegressor(**lgb_params)\n",
        "    model_lgb.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], callbacks=[log_evaluation(500)])\n",
        "    joblib.dump(model_lgb, f\"{MODEL_DIR}/lgb_fold{fold}.pkl\")\n",
        "    oof_preds[train.index[train.fold == fold]] += model_lgb.predict(x_valid) * 0.4\n",
        "\n",
        "    # CatBoost\n",
        "    model_cat = cb.CatBoostRegressor(**cat_params, verbose=500)\n",
        "    model_cat.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], verbose=500)\n",
        "    model_cat.save_model(f\"{MODEL_DIR}/cat_fold{fold}.cbm\")\n",
        "    oof_preds[train.index[train.fold == fold]] += model_cat.predict(x_valid) * 0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compute C-index**"
      ],
      "metadata": {
        "id": "M7p8AINeAiAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute C-index\n",
        "c_index = concordance_index(train[\"efs_time\"], -oof_preds, train[\"efs\"])\n",
        "print(f\"\\nOverall CV C-Index: {c_index:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_cBzpBsAiXX",
        "outputId": "7ae7a1ec-c4cd-48f0-e1c9-cff929ff23e4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Overall CV C-Index: 0.6853\n"
          ]
        }
      ]
    }
  ]
}